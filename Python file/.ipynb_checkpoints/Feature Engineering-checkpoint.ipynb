{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "all_data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#選擇我覺得有用的欄位\n",
    "cols = [ 'Sex','Age',\"SibSp\",'Pclass','Fare','Embarked','Parch','Survived']\n",
    "all_data = all_data[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Pclass        0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "Parch         0\n",
       "Survived      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢查空值\n",
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Pclass      0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "Parch       0\n",
       "Survived    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#填補空值\n",
    "mean_age = all_data['Age'].mean()\n",
    "all_data['Age'] = all_data['Age'].fillna(mean_age)\n",
    "# 移除Ebarked 空的欄位\n",
    "all_data.dropna(inplace=True)\n",
    "\n",
    "all_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "all_data['Sex'] = le.fit_transform(all_data['Sex'])\n",
    "all_data['Embarked'] = le.fit_transform(all_data['Embarked'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>889 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex        Age  SibSp  Pclass      Fare  Embarked  Parch\n",
       "0      1  22.000000      1       3    7.2500         2      0\n",
       "1      0  38.000000      1       1   71.2833         0      0\n",
       "2      0  26.000000      0       3    7.9250         2      0\n",
       "3      0  35.000000      1       1   53.1000         2      0\n",
       "4      1  35.000000      0       3    8.0500         2      0\n",
       "5      1  29.699118      0       3    8.4583         1      0\n",
       "6      1  54.000000      0       1   51.8625         2      0\n",
       "7      1   2.000000      3       3   21.0750         2      1\n",
       "8      0  27.000000      0       3   11.1333         2      2\n",
       "9      0  14.000000      1       2   30.0708         0      0\n",
       "10     0   4.000000      1       3   16.7000         2      1\n",
       "11     0  58.000000      0       1   26.5500         2      0\n",
       "12     1  20.000000      0       3    8.0500         2      0\n",
       "13     1  39.000000      1       3   31.2750         2      5\n",
       "14     0  14.000000      0       3    7.8542         2      0\n",
       "15     0  55.000000      0       2   16.0000         2      0\n",
       "16     1   2.000000      4       3   29.1250         1      1\n",
       "17     1  29.699118      0       2   13.0000         2      0\n",
       "18     0  31.000000      1       3   18.0000         2      0\n",
       "19     0  29.699118      0       3    7.2250         0      0\n",
       "20     1  35.000000      0       2   26.0000         2      0\n",
       "21     1  34.000000      0       2   13.0000         2      0\n",
       "22     0  15.000000      0       3    8.0292         1      0\n",
       "23     1  28.000000      0       1   35.5000         2      0\n",
       "24     0   8.000000      3       3   21.0750         2      1\n",
       "25     0  38.000000      1       3   31.3875         2      5\n",
       "26     1  29.699118      0       3    7.2250         0      0\n",
       "27     1  19.000000      3       1  263.0000         2      2\n",
       "28     0  29.699118      0       3    7.8792         1      0\n",
       "29     1  29.699118      0       3    7.8958         2      0\n",
       "..   ...        ...    ...     ...       ...       ...    ...\n",
       "861    1  21.000000      1       2   11.5000         2      0\n",
       "862    0  48.000000      0       1   25.9292         2      0\n",
       "863    0  29.699118      8       3   69.5500         2      2\n",
       "864    1  24.000000      0       2   13.0000         2      0\n",
       "865    0  42.000000      0       2   13.0000         2      0\n",
       "866    0  27.000000      1       2   13.8583         0      0\n",
       "867    1  31.000000      0       1   50.4958         2      0\n",
       "868    1  29.699118      0       3    9.5000         2      0\n",
       "869    1   4.000000      1       3   11.1333         2      1\n",
       "870    1  26.000000      0       3    7.8958         2      0\n",
       "871    0  47.000000      1       1   52.5542         2      1\n",
       "872    1  33.000000      0       1    5.0000         2      0\n",
       "873    1  47.000000      0       3    9.0000         2      0\n",
       "874    0  28.000000      1       2   24.0000         0      0\n",
       "875    0  15.000000      0       3    7.2250         0      0\n",
       "876    1  20.000000      0       3    9.8458         2      0\n",
       "877    1  19.000000      0       3    7.8958         2      0\n",
       "878    1  29.699118      0       3    7.8958         2      0\n",
       "879    0  56.000000      0       1   83.1583         0      1\n",
       "880    0  25.000000      0       2   26.0000         2      1\n",
       "881    1  33.000000      0       3    7.8958         2      0\n",
       "882    0  22.000000      0       3   10.5167         2      0\n",
       "883    1  28.000000      0       2   10.5000         2      0\n",
       "884    1  25.000000      0       3    7.0500         2      0\n",
       "885    0  39.000000      0       3   29.1250         1      5\n",
       "886    1  27.000000      0       2   13.0000         2      0\n",
       "887    0  19.000000      0       1   30.0000         2      0\n",
       "888    0  29.699118      1       3   23.4500         2      2\n",
       "889    1  26.000000      0       1   30.0000         0      0\n",
       "890    1  32.000000      0       3    7.7500         1      0\n",
       "\n",
       "[889 rows x 7 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = all_data['Survived']\n",
    "all_data = all_data.iloc[: ,:7]\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data ,y ,test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=40,input_dim = 7 , kernel_initializer = 'uniform' , activation = 'relu'))\n",
    "model.add(Dense(units=30 , kernel_initializer = 'uniform' , activation = 'relu'))\n",
    "model.add(Dense(units=1 , kernel_initializer = 'uniform' , activation = 'sigmoid'))\n",
    "# model.add(LeakyReLU(alpha=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy' , optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/400\n",
      " - 0s - loss: 0.6897 - accuracy: 0.6028 - val_loss: 0.6830 - val_accuracy: 0.6250\n",
      "Epoch 2/400\n",
      " - 0s - loss: 0.6769 - accuracy: 0.6917 - val_loss: 0.6698 - val_accuracy: 0.6125\n",
      "Epoch 3/400\n",
      " - 0s - loss: 0.6563 - accuracy: 0.6819 - val_loss: 0.6538 - val_accuracy: 0.6000\n",
      "Epoch 4/400\n",
      " - 0s - loss: 0.6305 - accuracy: 0.6806 - val_loss: 0.6390 - val_accuracy: 0.6125\n",
      "Epoch 5/400\n",
      " - 0s - loss: 0.6061 - accuracy: 0.6819 - val_loss: 0.6397 - val_accuracy: 0.6250\n",
      "Epoch 6/400\n",
      " - 0s - loss: 0.5916 - accuracy: 0.6917 - val_loss: 0.6501 - val_accuracy: 0.6250\n",
      "Epoch 7/400\n",
      " - 0s - loss: 0.5850 - accuracy: 0.6944 - val_loss: 0.6553 - val_accuracy: 0.6125\n",
      "Epoch 8/400\n",
      " - 0s - loss: 0.5856 - accuracy: 0.6958 - val_loss: 0.6538 - val_accuracy: 0.6125\n",
      "Epoch 9/400\n",
      " - 0s - loss: 0.5819 - accuracy: 0.6972 - val_loss: 0.6462 - val_accuracy: 0.6125\n",
      "Epoch 10/400\n",
      " - 0s - loss: 0.5802 - accuracy: 0.6944 - val_loss: 0.6429 - val_accuracy: 0.6125\n",
      "Epoch 11/400\n",
      " - 0s - loss: 0.5772 - accuracy: 0.6986 - val_loss: 0.6333 - val_accuracy: 0.6125\n",
      "Epoch 12/400\n",
      " - 0s - loss: 0.5765 - accuracy: 0.7014 - val_loss: 0.6290 - val_accuracy: 0.6125\n",
      "Epoch 13/400\n",
      " - 0s - loss: 0.5752 - accuracy: 0.7083 - val_loss: 0.6326 - val_accuracy: 0.6125\n",
      "Epoch 14/400\n",
      " - 0s - loss: 0.5723 - accuracy: 0.7028 - val_loss: 0.6263 - val_accuracy: 0.6125\n",
      "Epoch 15/400\n",
      " - 0s - loss: 0.5703 - accuracy: 0.7125 - val_loss: 0.6293 - val_accuracy: 0.6250\n",
      "Epoch 16/400\n",
      " - 0s - loss: 0.5680 - accuracy: 0.7181 - val_loss: 0.6263 - val_accuracy: 0.6250\n",
      "Epoch 17/400\n",
      " - 0s - loss: 0.5663 - accuracy: 0.7194 - val_loss: 0.6172 - val_accuracy: 0.6250\n",
      "Epoch 18/400\n",
      " - 0s - loss: 0.5637 - accuracy: 0.7181 - val_loss: 0.6172 - val_accuracy: 0.6375\n",
      "Epoch 19/400\n",
      " - 0s - loss: 0.5610 - accuracy: 0.7250 - val_loss: 0.6139 - val_accuracy: 0.6250\n",
      "Epoch 20/400\n",
      " - 0s - loss: 0.5584 - accuracy: 0.7278 - val_loss: 0.6092 - val_accuracy: 0.6250\n",
      "Epoch 21/400\n",
      " - 0s - loss: 0.5541 - accuracy: 0.7250 - val_loss: 0.6128 - val_accuracy: 0.6250\n",
      "Epoch 22/400\n",
      " - 0s - loss: 0.5513 - accuracy: 0.7278 - val_loss: 0.6070 - val_accuracy: 0.6125\n",
      "Epoch 23/400\n",
      " - 0s - loss: 0.5492 - accuracy: 0.7292 - val_loss: 0.5956 - val_accuracy: 0.6250\n",
      "Epoch 24/400\n",
      " - 0s - loss: 0.5443 - accuracy: 0.7250 - val_loss: 0.5972 - val_accuracy: 0.6250\n",
      "Epoch 25/400\n",
      " - 0s - loss: 0.5423 - accuracy: 0.7236 - val_loss: 0.5854 - val_accuracy: 0.6125\n",
      "Epoch 26/400\n",
      " - 0s - loss: 0.5447 - accuracy: 0.7306 - val_loss: 0.5795 - val_accuracy: 0.6250\n",
      "Epoch 27/400\n",
      " - 0s - loss: 0.5347 - accuracy: 0.7278 - val_loss: 0.5804 - val_accuracy: 0.6125\n",
      "Epoch 28/400\n",
      " - 0s - loss: 0.5362 - accuracy: 0.7208 - val_loss: 0.5721 - val_accuracy: 0.6125\n",
      "Epoch 29/400\n",
      " - 0s - loss: 0.5279 - accuracy: 0.7264 - val_loss: 0.5666 - val_accuracy: 0.6250\n",
      "Epoch 30/400\n",
      " - 0s - loss: 0.5267 - accuracy: 0.7278 - val_loss: 0.5652 - val_accuracy: 0.6125\n",
      "Epoch 31/400\n",
      " - 0s - loss: 0.5262 - accuracy: 0.7319 - val_loss: 0.5581 - val_accuracy: 0.6625\n",
      "Epoch 32/400\n",
      " - 0s - loss: 0.5162 - accuracy: 0.7222 - val_loss: 0.5624 - val_accuracy: 0.6125\n",
      "Epoch 33/400\n",
      " - 0s - loss: 0.5176 - accuracy: 0.7306 - val_loss: 0.5479 - val_accuracy: 0.6625\n",
      "Epoch 34/400\n",
      " - 0s - loss: 0.5113 - accuracy: 0.7250 - val_loss: 0.5398 - val_accuracy: 0.6625\n",
      "Epoch 35/400\n",
      " - 0s - loss: 0.5076 - accuracy: 0.7458 - val_loss: 0.5316 - val_accuracy: 0.6625\n",
      "Epoch 36/400\n",
      " - 0s - loss: 0.5094 - accuracy: 0.7292 - val_loss: 0.5281 - val_accuracy: 0.6625\n",
      "Epoch 37/400\n",
      " - 0s - loss: 0.5005 - accuracy: 0.7444 - val_loss: 0.5239 - val_accuracy: 0.7000\n",
      "Epoch 38/400\n",
      " - 0s - loss: 0.4988 - accuracy: 0.7625 - val_loss: 0.5169 - val_accuracy: 0.7000\n",
      "Epoch 39/400\n",
      " - 0s - loss: 0.4967 - accuracy: 0.7444 - val_loss: 0.5117 - val_accuracy: 0.6750\n",
      "Epoch 40/400\n",
      " - 0s - loss: 0.4914 - accuracy: 0.7694 - val_loss: 0.5066 - val_accuracy: 0.7375\n",
      "Epoch 41/400\n",
      " - 0s - loss: 0.4874 - accuracy: 0.7667 - val_loss: 0.5035 - val_accuracy: 0.7250\n",
      "Epoch 42/400\n",
      " - 0s - loss: 0.4824 - accuracy: 0.7722 - val_loss: 0.4966 - val_accuracy: 0.7250\n",
      "Epoch 43/400\n",
      " - 0s - loss: 0.4794 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7625\n",
      "Epoch 44/400\n",
      " - 0s - loss: 0.4815 - accuracy: 0.7875 - val_loss: 0.4751 - val_accuracy: 0.7875\n",
      "Epoch 45/400\n",
      " - 0s - loss: 0.4717 - accuracy: 0.7917 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
      "Epoch 46/400\n",
      " - 0s - loss: 0.4682 - accuracy: 0.8000 - val_loss: 0.4616 - val_accuracy: 0.8250\n",
      "Epoch 47/400\n",
      " - 0s - loss: 0.4706 - accuracy: 0.7986 - val_loss: 0.4649 - val_accuracy: 0.7750\n",
      "Epoch 48/400\n",
      " - 0s - loss: 0.4675 - accuracy: 0.7972 - val_loss: 0.4544 - val_accuracy: 0.8250\n",
      "Epoch 49/400\n",
      " - 0s - loss: 0.4607 - accuracy: 0.8042 - val_loss: 0.4487 - val_accuracy: 0.8250\n",
      "Epoch 50/400\n",
      " - 0s - loss: 0.4587 - accuracy: 0.7958 - val_loss: 0.4444 - val_accuracy: 0.8250\n",
      "Epoch 51/400\n",
      " - 0s - loss: 0.4603 - accuracy: 0.7986 - val_loss: 0.4384 - val_accuracy: 0.8375\n",
      "Epoch 52/400\n",
      " - 0s - loss: 0.4529 - accuracy: 0.8097 - val_loss: 0.4320 - val_accuracy: 0.8375\n",
      "Epoch 53/400\n",
      " - 0s - loss: 0.4520 - accuracy: 0.7958 - val_loss: 0.4362 - val_accuracy: 0.8125\n",
      "Epoch 54/400\n",
      " - 0s - loss: 0.4539 - accuracy: 0.7944 - val_loss: 0.4454 - val_accuracy: 0.8250\n",
      "Epoch 55/400\n",
      " - 0s - loss: 0.4533 - accuracy: 0.8042 - val_loss: 0.4247 - val_accuracy: 0.8250\n",
      "Epoch 56/400\n",
      " - 0s - loss: 0.4473 - accuracy: 0.8000 - val_loss: 0.4234 - val_accuracy: 0.8375\n",
      "Epoch 57/400\n",
      " - 0s - loss: 0.4476 - accuracy: 0.8014 - val_loss: 0.4150 - val_accuracy: 0.8250\n",
      "Epoch 58/400\n",
      " - 0s - loss: 0.4485 - accuracy: 0.8014 - val_loss: 0.4091 - val_accuracy: 0.8375\n",
      "Epoch 59/400\n",
      " - 0s - loss: 0.4455 - accuracy: 0.8000 - val_loss: 0.4071 - val_accuracy: 0.8375\n",
      "Epoch 60/400\n",
      " - 0s - loss: 0.4482 - accuracy: 0.8083 - val_loss: 0.4150 - val_accuracy: 0.8250\n",
      "Epoch 61/400\n",
      " - 0s - loss: 0.4430 - accuracy: 0.8014 - val_loss: 0.4081 - val_accuracy: 0.8375\n",
      "Epoch 62/400\n",
      " - 0s - loss: 0.4447 - accuracy: 0.7986 - val_loss: 0.4052 - val_accuracy: 0.8500\n",
      "Epoch 63/400\n",
      " - 0s - loss: 0.4436 - accuracy: 0.8028 - val_loss: 0.4039 - val_accuracy: 0.8125\n",
      "Epoch 64/400\n",
      " - 0s - loss: 0.4445 - accuracy: 0.7958 - val_loss: 0.4146 - val_accuracy: 0.8375\n",
      "Epoch 65/400\n",
      " - 0s - loss: 0.4416 - accuracy: 0.8125 - val_loss: 0.4104 - val_accuracy: 0.8125\n",
      "Epoch 66/400\n",
      " - 0s - loss: 0.4402 - accuracy: 0.8028 - val_loss: 0.4072 - val_accuracy: 0.8500\n",
      "Epoch 67/400\n",
      " - 0s - loss: 0.4418 - accuracy: 0.8042 - val_loss: 0.4001 - val_accuracy: 0.8375\n",
      "Epoch 68/400\n",
      " - 0s - loss: 0.4394 - accuracy: 0.8069 - val_loss: 0.4012 - val_accuracy: 0.8500\n",
      "Epoch 69/400\n",
      " - 0s - loss: 0.4414 - accuracy: 0.8153 - val_loss: 0.4014 - val_accuracy: 0.8125\n",
      "Epoch 70/400\n",
      " - 0s - loss: 0.4495 - accuracy: 0.7986 - val_loss: 0.4013 - val_accuracy: 0.8500\n",
      "Epoch 71/400\n",
      " - 0s - loss: 0.4398 - accuracy: 0.8042 - val_loss: 0.3945 - val_accuracy: 0.8375\n",
      "Epoch 72/400\n",
      " - 0s - loss: 0.4413 - accuracy: 0.7972 - val_loss: 0.3933 - val_accuracy: 0.8375\n",
      "Epoch 73/400\n",
      " - 0s - loss: 0.4403 - accuracy: 0.8069 - val_loss: 0.3963 - val_accuracy: 0.8500\n",
      "Epoch 74/400\n",
      " - 0s - loss: 0.4342 - accuracy: 0.8056 - val_loss: 0.3951 - val_accuracy: 0.8375\n",
      "Epoch 75/400\n",
      " - 0s - loss: 0.4349 - accuracy: 0.8042 - val_loss: 0.4044 - val_accuracy: 0.8375\n",
      "Epoch 76/400\n",
      " - 0s - loss: 0.4382 - accuracy: 0.8125 - val_loss: 0.4025 - val_accuracy: 0.8250\n",
      "Epoch 77/400\n",
      " - 0s - loss: 0.4353 - accuracy: 0.8069 - val_loss: 0.3964 - val_accuracy: 0.8375\n",
      "Epoch 78/400\n",
      " - 0s - loss: 0.4382 - accuracy: 0.8000 - val_loss: 0.3990 - val_accuracy: 0.8500\n",
      "Epoch 79/400\n",
      " - 0s - loss: 0.4340 - accuracy: 0.8111 - val_loss: 0.3967 - val_accuracy: 0.8250\n",
      "Epoch 80/400\n",
      " - 0s - loss: 0.4340 - accuracy: 0.8125 - val_loss: 0.3990 - val_accuracy: 0.8500\n",
      "Epoch 81/400\n",
      " - 0s - loss: 0.4365 - accuracy: 0.8028 - val_loss: 0.3859 - val_accuracy: 0.8375\n",
      "Epoch 82/400\n",
      " - 0s - loss: 0.4328 - accuracy: 0.8028 - val_loss: 0.3879 - val_accuracy: 0.8375\n",
      "Epoch 83/400\n",
      " - 0s - loss: 0.4351 - accuracy: 0.8097 - val_loss: 0.3944 - val_accuracy: 0.8250\n",
      "Epoch 84/400\n",
      " - 0s - loss: 0.4337 - accuracy: 0.8153 - val_loss: 0.3870 - val_accuracy: 0.8500\n",
      "Epoch 85/400\n",
      " - 0s - loss: 0.4321 - accuracy: 0.8069 - val_loss: 0.3899 - val_accuracy: 0.8500\n",
      "Epoch 86/400\n",
      " - 0s - loss: 0.4352 - accuracy: 0.8111 - val_loss: 0.3941 - val_accuracy: 0.8250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/400\n",
      " - 0s - loss: 0.4317 - accuracy: 0.8083 - val_loss: 0.3872 - val_accuracy: 0.8375\n",
      "Epoch 88/400\n",
      " - 0s - loss: 0.4307 - accuracy: 0.8097 - val_loss: 0.3848 - val_accuracy: 0.8500\n",
      "Epoch 89/400\n",
      " - 0s - loss: 0.4336 - accuracy: 0.8014 - val_loss: 0.3910 - val_accuracy: 0.8500\n",
      "Epoch 90/400\n",
      " - 0s - loss: 0.4448 - accuracy: 0.8083 - val_loss: 0.3871 - val_accuracy: 0.8250\n",
      "Epoch 91/400\n",
      " - 0s - loss: 0.4425 - accuracy: 0.7944 - val_loss: 0.4191 - val_accuracy: 0.8125\n",
      "Epoch 92/400\n",
      " - 0s - loss: 0.4440 - accuracy: 0.8069 - val_loss: 0.4086 - val_accuracy: 0.8250\n",
      "Epoch 93/400\n",
      " - 0s - loss: 0.4337 - accuracy: 0.8083 - val_loss: 0.4038 - val_accuracy: 0.8500\n",
      "Epoch 94/400\n",
      " - 0s - loss: 0.4285 - accuracy: 0.8167 - val_loss: 0.3912 - val_accuracy: 0.8250\n",
      "Epoch 95/400\n",
      " - 0s - loss: 0.4316 - accuracy: 0.8097 - val_loss: 0.3912 - val_accuracy: 0.8500\n",
      "Epoch 96/400\n",
      " - 0s - loss: 0.4294 - accuracy: 0.8069 - val_loss: 0.3983 - val_accuracy: 0.8500\n",
      "Epoch 97/400\n",
      " - 0s - loss: 0.4304 - accuracy: 0.8167 - val_loss: 0.3890 - val_accuracy: 0.8250\n",
      "Epoch 98/400\n",
      " - 0s - loss: 0.4290 - accuracy: 0.8153 - val_loss: 0.3874 - val_accuracy: 0.8250\n",
      "Epoch 99/400\n",
      " - 0s - loss: 0.4315 - accuracy: 0.8042 - val_loss: 0.4029 - val_accuracy: 0.8250\n",
      "Epoch 100/400\n",
      " - 0s - loss: 0.4356 - accuracy: 0.8153 - val_loss: 0.3838 - val_accuracy: 0.8250\n",
      "Epoch 101/400\n",
      " - 0s - loss: 0.4306 - accuracy: 0.8069 - val_loss: 0.4001 - val_accuracy: 0.8500\n",
      "Epoch 102/400\n",
      " - 0s - loss: 0.4373 - accuracy: 0.8167 - val_loss: 0.3838 - val_accuracy: 0.8250\n",
      "Epoch 103/400\n",
      " - 0s - loss: 0.4311 - accuracy: 0.8069 - val_loss: 0.4082 - val_accuracy: 0.8250\n",
      "Epoch 104/400\n",
      " - 0s - loss: 0.4327 - accuracy: 0.8069 - val_loss: 0.3916 - val_accuracy: 0.8250\n",
      "Epoch 105/400\n",
      " - 0s - loss: 0.4308 - accuracy: 0.8111 - val_loss: 0.3994 - val_accuracy: 0.8500\n",
      "Epoch 106/400\n",
      " - 0s - loss: 0.4273 - accuracy: 0.8153 - val_loss: 0.3856 - val_accuracy: 0.8250\n",
      "Epoch 107/400\n",
      " - 0s - loss: 0.4340 - accuracy: 0.7944 - val_loss: 0.3873 - val_accuracy: 0.8500\n",
      "Epoch 108/400\n",
      " - 0s - loss: 0.4300 - accuracy: 0.8194 - val_loss: 0.3808 - val_accuracy: 0.8250\n",
      "Epoch 109/400\n",
      " - 0s - loss: 0.4245 - accuracy: 0.8139 - val_loss: 0.3800 - val_accuracy: 0.8375\n",
      "Epoch 110/400\n",
      " - 0s - loss: 0.4237 - accuracy: 0.8111 - val_loss: 0.3808 - val_accuracy: 0.8375\n",
      "Epoch 111/400\n",
      " - 0s - loss: 0.4222 - accuracy: 0.8153 - val_loss: 0.3855 - val_accuracy: 0.8375\n",
      "Epoch 112/400\n",
      " - 0s - loss: 0.4224 - accuracy: 0.8153 - val_loss: 0.3854 - val_accuracy: 0.8250\n",
      "Epoch 113/400\n",
      " - 0s - loss: 0.4230 - accuracy: 0.8194 - val_loss: 0.3855 - val_accuracy: 0.8375\n",
      "Epoch 114/400\n",
      " - 0s - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.3913 - val_accuracy: 0.8250\n",
      "Epoch 115/400\n",
      " - 0s - loss: 0.4439 - accuracy: 0.8069 - val_loss: 0.3891 - val_accuracy: 0.8375\n",
      "Epoch 116/400\n",
      " - 0s - loss: 0.4384 - accuracy: 0.8042 - val_loss: 0.3905 - val_accuracy: 0.8625\n",
      "Epoch 117/400\n",
      " - 0s - loss: 0.4271 - accuracy: 0.8181 - val_loss: 0.3842 - val_accuracy: 0.8375\n",
      "Epoch 118/400\n",
      " - 0s - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.3849 - val_accuracy: 0.8500\n",
      "Epoch 119/400\n",
      " - 0s - loss: 0.4242 - accuracy: 0.8181 - val_loss: 0.3829 - val_accuracy: 0.8375\n",
      "Epoch 120/400\n",
      " - 0s - loss: 0.4275 - accuracy: 0.8139 - val_loss: 0.3815 - val_accuracy: 0.8500\n",
      "Epoch 121/400\n",
      " - 0s - loss: 0.4207 - accuracy: 0.8139 - val_loss: 0.3777 - val_accuracy: 0.8625\n",
      "Epoch 122/400\n",
      " - 0s - loss: 0.4242 - accuracy: 0.8167 - val_loss: 0.3750 - val_accuracy: 0.8500\n",
      "Epoch 123/400\n",
      " - 0s - loss: 0.4213 - accuracy: 0.8097 - val_loss: 0.3819 - val_accuracy: 0.8625\n",
      "Epoch 124/400\n",
      " - 0s - loss: 0.4294 - accuracy: 0.8167 - val_loss: 0.3792 - val_accuracy: 0.8375\n",
      "Epoch 125/400\n",
      " - 0s - loss: 0.4210 - accuracy: 0.8181 - val_loss: 0.3758 - val_accuracy: 0.8500\n",
      "Epoch 126/400\n",
      " - 0s - loss: 0.4241 - accuracy: 0.8153 - val_loss: 0.3868 - val_accuracy: 0.8625\n",
      "Epoch 127/400\n",
      " - 0s - loss: 0.4301 - accuracy: 0.8111 - val_loss: 0.3727 - val_accuracy: 0.8375\n",
      "Epoch 128/400\n",
      " - 0s - loss: 0.4208 - accuracy: 0.8139 - val_loss: 0.3779 - val_accuracy: 0.8625\n",
      "Epoch 129/400\n",
      " - 0s - loss: 0.4211 - accuracy: 0.8139 - val_loss: 0.3735 - val_accuracy: 0.8500\n",
      "Epoch 130/400\n",
      " - 0s - loss: 0.4191 - accuracy: 0.8167 - val_loss: 0.3739 - val_accuracy: 0.8625\n",
      "Epoch 131/400\n",
      " - 0s - loss: 0.4175 - accuracy: 0.8181 - val_loss: 0.3726 - val_accuracy: 0.8375\n",
      "Epoch 132/400\n",
      " - 0s - loss: 0.4206 - accuracy: 0.8056 - val_loss: 0.3770 - val_accuracy: 0.8500\n",
      "Epoch 133/400\n",
      " - 0s - loss: 0.4172 - accuracy: 0.8153 - val_loss: 0.3751 - val_accuracy: 0.8375\n",
      "Epoch 134/400\n",
      " - 0s - loss: 0.4169 - accuracy: 0.8181 - val_loss: 0.3760 - val_accuracy: 0.8375\n",
      "Epoch 135/400\n",
      " - 0s - loss: 0.4173 - accuracy: 0.8139 - val_loss: 0.3748 - val_accuracy: 0.8375\n",
      "Epoch 136/400\n",
      " - 0s - loss: 0.4197 - accuracy: 0.8083 - val_loss: 0.3721 - val_accuracy: 0.8500\n",
      "Epoch 137/400\n",
      " - 0s - loss: 0.4174 - accuracy: 0.8194 - val_loss: 0.3711 - val_accuracy: 0.8625\n",
      "Epoch 138/400\n",
      " - 0s - loss: 0.4286 - accuracy: 0.8208 - val_loss: 0.3760 - val_accuracy: 0.8375\n",
      "Epoch 139/400\n",
      " - 0s - loss: 0.4168 - accuracy: 0.8208 - val_loss: 0.3827 - val_accuracy: 0.8375\n",
      "Epoch 140/400\n",
      " - 0s - loss: 0.4255 - accuracy: 0.8097 - val_loss: 0.3835 - val_accuracy: 0.8375\n",
      "Epoch 141/400\n",
      " - 0s - loss: 0.4241 - accuracy: 0.8194 - val_loss: 0.3725 - val_accuracy: 0.8375\n",
      "Epoch 142/400\n",
      " - 0s - loss: 0.4218 - accuracy: 0.8056 - val_loss: 0.3744 - val_accuracy: 0.8625\n",
      "Epoch 143/400\n",
      " - 0s - loss: 0.4325 - accuracy: 0.8153 - val_loss: 0.3830 - val_accuracy: 0.8375\n",
      "Epoch 144/400\n",
      " - 0s - loss: 0.4272 - accuracy: 0.8125 - val_loss: 0.3767 - val_accuracy: 0.8625\n",
      "Epoch 145/400\n",
      " - 0s - loss: 0.4176 - accuracy: 0.8181 - val_loss: 0.3677 - val_accuracy: 0.8375\n",
      "Epoch 146/400\n",
      " - 0s - loss: 0.4156 - accuracy: 0.8139 - val_loss: 0.3864 - val_accuracy: 0.8500\n",
      "Epoch 147/400\n",
      " - 0s - loss: 0.4325 - accuracy: 0.8139 - val_loss: 0.3830 - val_accuracy: 0.8500\n",
      "Epoch 148/400\n",
      " - 0s - loss: 0.4385 - accuracy: 0.7931 - val_loss: 0.3769 - val_accuracy: 0.8625\n",
      "Epoch 149/400\n",
      " - 0s - loss: 0.4291 - accuracy: 0.8236 - val_loss: 0.3657 - val_accuracy: 0.8625\n",
      "Epoch 150/400\n",
      " - 0s - loss: 0.4179 - accuracy: 0.8083 - val_loss: 0.3684 - val_accuracy: 0.8375\n",
      "Epoch 151/400\n",
      " - 0s - loss: 0.4151 - accuracy: 0.8222 - val_loss: 0.3703 - val_accuracy: 0.8625\n",
      "Epoch 152/400\n",
      " - 0s - loss: 0.4158 - accuracy: 0.8125 - val_loss: 0.3667 - val_accuracy: 0.8625\n",
      "Epoch 153/400\n",
      " - 0s - loss: 0.4142 - accuracy: 0.8222 - val_loss: 0.3652 - val_accuracy: 0.8500\n",
      "Epoch 154/400\n",
      " - 0s - loss: 0.4132 - accuracy: 0.8167 - val_loss: 0.3649 - val_accuracy: 0.8500\n",
      "Epoch 155/400\n",
      " - 0s - loss: 0.4131 - accuracy: 0.8153 - val_loss: 0.3714 - val_accuracy: 0.8625\n",
      "Epoch 156/400\n",
      " - 0s - loss: 0.4184 - accuracy: 0.8194 - val_loss: 0.3615 - val_accuracy: 0.8375\n",
      "Epoch 157/400\n",
      " - 0s - loss: 0.4152 - accuracy: 0.8083 - val_loss: 0.3677 - val_accuracy: 0.8625\n",
      "Epoch 158/400\n",
      " - 0s - loss: 0.4152 - accuracy: 0.8250 - val_loss: 0.3696 - val_accuracy: 0.8500\n",
      "Epoch 159/400\n",
      " - 0s - loss: 0.4148 - accuracy: 0.8236 - val_loss: 0.3644 - val_accuracy: 0.8375\n",
      "Epoch 160/400\n",
      " - 0s - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.3664 - val_accuracy: 0.8500\n",
      "Epoch 161/400\n",
      " - 0s - loss: 0.4145 - accuracy: 0.8222 - val_loss: 0.3660 - val_accuracy: 0.8375\n",
      "Epoch 162/400\n",
      " - 0s - loss: 0.4193 - accuracy: 0.8139 - val_loss: 0.3694 - val_accuracy: 0.8500\n",
      "Epoch 163/400\n",
      " - 0s - loss: 0.4193 - accuracy: 0.8139 - val_loss: 0.3595 - val_accuracy: 0.8375\n",
      "Epoch 164/400\n",
      " - 0s - loss: 0.4201 - accuracy: 0.8000 - val_loss: 0.3641 - val_accuracy: 0.8500\n",
      "Epoch 165/400\n",
      " - 0s - loss: 0.4137 - accuracy: 0.8181 - val_loss: 0.3658 - val_accuracy: 0.8375\n",
      "Epoch 166/400\n",
      " - 0s - loss: 0.4224 - accuracy: 0.7972 - val_loss: 0.3646 - val_accuracy: 0.8625\n",
      "Epoch 167/400\n",
      " - 0s - loss: 0.4176 - accuracy: 0.8236 - val_loss: 0.3519 - val_accuracy: 0.8375\n",
      "Epoch 168/400\n",
      " - 0s - loss: 0.4151 - accuracy: 0.8125 - val_loss: 0.3645 - val_accuracy: 0.8625\n",
      "Epoch 169/400\n",
      " - 0s - loss: 0.4153 - accuracy: 0.8167 - val_loss: 0.3574 - val_accuracy: 0.8375\n",
      "Epoch 170/400\n",
      " - 0s - loss: 0.4226 - accuracy: 0.8139 - val_loss: 0.3517 - val_accuracy: 0.8625\n",
      "Epoch 171/400\n",
      " - 0s - loss: 0.4146 - accuracy: 0.8083 - val_loss: 0.3516 - val_accuracy: 0.8500\n",
      "Epoch 172/400\n",
      " - 0s - loss: 0.4285 - accuracy: 0.8222 - val_loss: 0.3563 - val_accuracy: 0.8375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/400\n",
      " - 0s - loss: 0.4187 - accuracy: 0.8139 - val_loss: 0.3513 - val_accuracy: 0.8625\n",
      "Epoch 174/400\n",
      " - 0s - loss: 0.4136 - accuracy: 0.8236 - val_loss: 0.3468 - val_accuracy: 0.8375\n",
      "Epoch 175/400\n",
      " - 0s - loss: 0.4107 - accuracy: 0.8222 - val_loss: 0.3602 - val_accuracy: 0.8625\n",
      "Epoch 176/400\n",
      " - 0s - loss: 0.4133 - accuracy: 0.8236 - val_loss: 0.3648 - val_accuracy: 0.8375\n",
      "Epoch 177/400\n",
      " - 0s - loss: 0.4155 - accuracy: 0.8167 - val_loss: 0.3567 - val_accuracy: 0.8375\n",
      "Epoch 178/400\n",
      " - 0s - loss: 0.4131 - accuracy: 0.8111 - val_loss: 0.3560 - val_accuracy: 0.8500\n",
      "Epoch 179/400\n",
      " - 0s - loss: 0.4084 - accuracy: 0.8208 - val_loss: 0.3577 - val_accuracy: 0.8625\n",
      "Epoch 180/400\n",
      " - 0s - loss: 0.4147 - accuracy: 0.8153 - val_loss: 0.3633 - val_accuracy: 0.8375\n",
      "Epoch 181/400\n",
      " - 0s - loss: 0.4106 - accuracy: 0.8181 - val_loss: 0.3606 - val_accuracy: 0.8375\n",
      "Epoch 182/400\n",
      " - 0s - loss: 0.4078 - accuracy: 0.8236 - val_loss: 0.3654 - val_accuracy: 0.8375\n",
      "Epoch 183/400\n",
      " - 0s - loss: 0.4097 - accuracy: 0.8181 - val_loss: 0.3656 - val_accuracy: 0.8500\n",
      "Epoch 184/400\n",
      " - 0s - loss: 0.4129 - accuracy: 0.8167 - val_loss: 0.3641 - val_accuracy: 0.8375\n",
      "Epoch 185/400\n",
      " - 0s - loss: 0.4142 - accuracy: 0.8222 - val_loss: 0.3628 - val_accuracy: 0.8375\n",
      "Epoch 186/400\n",
      " - 0s - loss: 0.4082 - accuracy: 0.8208 - val_loss: 0.3590 - val_accuracy: 0.8500\n",
      "Epoch 187/400\n",
      " - 0s - loss: 0.4078 - accuracy: 0.8292 - val_loss: 0.3569 - val_accuracy: 0.8500\n",
      "Epoch 188/400\n",
      " - 0s - loss: 0.4069 - accuracy: 0.8222 - val_loss: 0.3567 - val_accuracy: 0.8375\n",
      "Epoch 189/400\n",
      " - 0s - loss: 0.4062 - accuracy: 0.8250 - val_loss: 0.3671 - val_accuracy: 0.8500\n",
      "Epoch 190/400\n",
      " - 0s - loss: 0.4072 - accuracy: 0.8292 - val_loss: 0.3609 - val_accuracy: 0.8375\n",
      "Epoch 191/400\n",
      " - 0s - loss: 0.4094 - accuracy: 0.8139 - val_loss: 0.3602 - val_accuracy: 0.8625\n",
      "Epoch 192/400\n",
      " - 0s - loss: 0.4071 - accuracy: 0.8292 - val_loss: 0.3565 - val_accuracy: 0.8500\n",
      "Epoch 193/400\n",
      " - 0s - loss: 0.4090 - accuracy: 0.8264 - val_loss: 0.3583 - val_accuracy: 0.8375\n",
      "Epoch 194/400\n",
      " - 0s - loss: 0.4099 - accuracy: 0.8181 - val_loss: 0.3581 - val_accuracy: 0.8625\n",
      "Epoch 195/400\n",
      " - 0s - loss: 0.4068 - accuracy: 0.8278 - val_loss: 0.3512 - val_accuracy: 0.8625\n",
      "Epoch 196/400\n",
      " - 0s - loss: 0.4060 - accuracy: 0.8222 - val_loss: 0.3527 - val_accuracy: 0.8625\n",
      "Epoch 197/400\n",
      " - 0s - loss: 0.4085 - accuracy: 0.8347 - val_loss: 0.3543 - val_accuracy: 0.8750\n",
      "Epoch 198/400\n",
      " - 0s - loss: 0.4078 - accuracy: 0.8167 - val_loss: 0.3630 - val_accuracy: 0.8500\n",
      "Epoch 199/400\n",
      " - 0s - loss: 0.4134 - accuracy: 0.8264 - val_loss: 0.3578 - val_accuracy: 0.8750\n",
      "Epoch 200/400\n",
      " - 0s - loss: 0.4193 - accuracy: 0.8014 - val_loss: 0.3849 - val_accuracy: 0.8750\n",
      "Epoch 201/400\n",
      " - 0s - loss: 0.4371 - accuracy: 0.8069 - val_loss: 0.3754 - val_accuracy: 0.8750\n",
      "Epoch 202/400\n",
      " - 0s - loss: 0.4139 - accuracy: 0.8208 - val_loss: 0.3642 - val_accuracy: 0.8625\n",
      "Epoch 203/400\n",
      " - 0s - loss: 0.4077 - accuracy: 0.8292 - val_loss: 0.3565 - val_accuracy: 0.8375\n",
      "Epoch 204/400\n",
      " - 0s - loss: 0.4069 - accuracy: 0.8319 - val_loss: 0.3512 - val_accuracy: 0.8500\n",
      "Epoch 205/400\n",
      " - 0s - loss: 0.4056 - accuracy: 0.8250 - val_loss: 0.3505 - val_accuracy: 0.8375\n",
      "Epoch 206/400\n",
      " - 0s - loss: 0.4042 - accuracy: 0.8319 - val_loss: 0.3594 - val_accuracy: 0.8375\n",
      "Epoch 207/400\n",
      " - 0s - loss: 0.4093 - accuracy: 0.8222 - val_loss: 0.3613 - val_accuracy: 0.8500\n",
      "Epoch 208/400\n",
      " - 0s - loss: 0.4069 - accuracy: 0.8264 - val_loss: 0.3502 - val_accuracy: 0.8625\n",
      "Epoch 209/400\n",
      " - 0s - loss: 0.4092 - accuracy: 0.8236 - val_loss: 0.3581 - val_accuracy: 0.8500\n",
      "Epoch 210/400\n",
      " - 0s - loss: 0.4056 - accuracy: 0.8208 - val_loss: 0.3631 - val_accuracy: 0.8625\n",
      "Epoch 211/400\n",
      " - 0s - loss: 0.4209 - accuracy: 0.8236 - val_loss: 0.3675 - val_accuracy: 0.8750\n",
      "Epoch 212/400\n",
      " - 0s - loss: 0.4065 - accuracy: 0.8222 - val_loss: 0.3578 - val_accuracy: 0.8750\n",
      "Epoch 213/400\n",
      " - 0s - loss: 0.4058 - accuracy: 0.8306 - val_loss: 0.3551 - val_accuracy: 0.8625\n",
      "Epoch 214/400\n",
      " - 0s - loss: 0.4045 - accuracy: 0.8264 - val_loss: 0.3543 - val_accuracy: 0.8750\n",
      "Epoch 215/400\n",
      " - 0s - loss: 0.4036 - accuracy: 0.8347 - val_loss: 0.3566 - val_accuracy: 0.8750\n",
      "Epoch 216/400\n",
      " - 0s - loss: 0.4050 - accuracy: 0.8333 - val_loss: 0.3553 - val_accuracy: 0.8625\n",
      "Epoch 217/400\n",
      " - 0s - loss: 0.4047 - accuracy: 0.8278 - val_loss: 0.3519 - val_accuracy: 0.8875\n",
      "Epoch 218/400\n",
      " - 0s - loss: 0.4031 - accuracy: 0.8347 - val_loss: 0.3527 - val_accuracy: 0.8750\n",
      "Epoch 219/400\n",
      " - 0s - loss: 0.4007 - accuracy: 0.8278 - val_loss: 0.3628 - val_accuracy: 0.8625\n",
      "Epoch 220/400\n",
      " - 0s - loss: 0.4018 - accuracy: 0.8319 - val_loss: 0.3591 - val_accuracy: 0.8750\n",
      "Epoch 221/400\n",
      " - 0s - loss: 0.4091 - accuracy: 0.8278 - val_loss: 0.3614 - val_accuracy: 0.8625\n",
      "Epoch 222/400\n",
      " - 0s - loss: 0.4045 - accuracy: 0.8264 - val_loss: 0.3556 - val_accuracy: 0.8625\n",
      "Epoch 223/400\n",
      " - 0s - loss: 0.4039 - accuracy: 0.8333 - val_loss: 0.3487 - val_accuracy: 0.8625\n",
      "Epoch 224/400\n",
      " - 0s - loss: 0.4070 - accuracy: 0.8292 - val_loss: 0.3575 - val_accuracy: 0.8625\n",
      "Epoch 225/400\n",
      " - 0s - loss: 0.4052 - accuracy: 0.8292 - val_loss: 0.3488 - val_accuracy: 0.8875\n",
      "Epoch 226/400\n",
      " - 0s - loss: 0.4008 - accuracy: 0.8319 - val_loss: 0.3461 - val_accuracy: 0.8625\n",
      "Epoch 227/400\n",
      " - 0s - loss: 0.4034 - accuracy: 0.8306 - val_loss: 0.3558 - val_accuracy: 0.8875\n",
      "Epoch 228/400\n",
      " - 0s - loss: 0.4118 - accuracy: 0.8333 - val_loss: 0.3665 - val_accuracy: 0.8750\n",
      "Epoch 229/400\n",
      " - 0s - loss: 0.4066 - accuracy: 0.8208 - val_loss: 0.3705 - val_accuracy: 0.8625\n",
      "Epoch 230/400\n",
      " - 0s - loss: 0.4104 - accuracy: 0.8319 - val_loss: 0.3659 - val_accuracy: 0.8750\n",
      "Epoch 231/400\n",
      " - 0s - loss: 0.4156 - accuracy: 0.8042 - val_loss: 0.3514 - val_accuracy: 0.8875\n",
      "Epoch 232/400\n",
      " - 0s - loss: 0.4054 - accuracy: 0.8347 - val_loss: 0.3585 - val_accuracy: 0.8625\n",
      "Epoch 233/400\n",
      " - 0s - loss: 0.4059 - accuracy: 0.8319 - val_loss: 0.3461 - val_accuracy: 0.8875\n",
      "Epoch 234/400\n",
      " - 0s - loss: 0.4047 - accuracy: 0.8306 - val_loss: 0.3476 - val_accuracy: 0.8625\n",
      "Epoch 235/400\n",
      " - 0s - loss: 0.4100 - accuracy: 0.8167 - val_loss: 0.3607 - val_accuracy: 0.9000\n",
      "Epoch 236/400\n",
      " - 0s - loss: 0.4147 - accuracy: 0.8292 - val_loss: 0.3699 - val_accuracy: 0.8750\n",
      "Epoch 237/400\n",
      " - 0s - loss: 0.4099 - accuracy: 0.8208 - val_loss: 0.3716 - val_accuracy: 0.8875\n",
      "Epoch 238/400\n",
      " - 0s - loss: 0.4174 - accuracy: 0.8278 - val_loss: 0.3632 - val_accuracy: 0.8625\n",
      "Epoch 239/400\n",
      " - 0s - loss: 0.4065 - accuracy: 0.8167 - val_loss: 0.3681 - val_accuracy: 0.8750\n",
      "Epoch 240/400\n",
      " - 0s - loss: 0.4168 - accuracy: 0.8319 - val_loss: 0.3677 - val_accuracy: 0.8750\n",
      "Epoch 241/400\n",
      " - 0s - loss: 0.4080 - accuracy: 0.8236 - val_loss: 0.3526 - val_accuracy: 0.8750\n",
      "Epoch 242/400\n",
      " - 0s - loss: 0.3996 - accuracy: 0.8333 - val_loss: 0.3457 - val_accuracy: 0.8750\n",
      "Epoch 243/400\n",
      " - 0s - loss: 0.3988 - accuracy: 0.8389 - val_loss: 0.3490 - val_accuracy: 0.8625\n",
      "Epoch 244/400\n",
      " - 0s - loss: 0.3987 - accuracy: 0.8333 - val_loss: 0.3520 - val_accuracy: 0.8875\n",
      "Epoch 245/400\n",
      " - 0s - loss: 0.4045 - accuracy: 0.8319 - val_loss: 0.3567 - val_accuracy: 0.8625\n",
      "Epoch 246/400\n",
      " - 0s - loss: 0.4039 - accuracy: 0.8181 - val_loss: 0.3627 - val_accuracy: 0.9000\n",
      "Epoch 247/400\n",
      " - 0s - loss: 0.4022 - accuracy: 0.8375 - val_loss: 0.3616 - val_accuracy: 0.8750\n",
      "Epoch 248/400\n",
      " - 0s - loss: 0.4033 - accuracy: 0.8264 - val_loss: 0.3534 - val_accuracy: 0.8750\n",
      "Epoch 249/400\n",
      " - 0s - loss: 0.4039 - accuracy: 0.8319 - val_loss: 0.3537 - val_accuracy: 0.8875\n",
      "Epoch 250/400\n",
      " - 0s - loss: 0.4051 - accuracy: 0.8319 - val_loss: 0.3529 - val_accuracy: 0.8625\n",
      "Epoch 251/400\n",
      " - 0s - loss: 0.4007 - accuracy: 0.8264 - val_loss: 0.3571 - val_accuracy: 0.8750\n",
      "Epoch 252/400\n",
      " - 0s - loss: 0.4004 - accuracy: 0.8306 - val_loss: 0.3416 - val_accuracy: 0.8750\n",
      "Epoch 253/400\n",
      " - 0s - loss: 0.3995 - accuracy: 0.8403 - val_loss: 0.3441 - val_accuracy: 0.8625\n",
      "Epoch 254/400\n",
      " - 0s - loss: 0.3981 - accuracy: 0.8347 - val_loss: 0.3469 - val_accuracy: 0.8750\n",
      "Epoch 255/400\n",
      " - 0s - loss: 0.3980 - accuracy: 0.8361 - val_loss: 0.3564 - val_accuracy: 0.8625\n",
      "Epoch 256/400\n",
      " - 0s - loss: 0.4003 - accuracy: 0.8292 - val_loss: 0.3571 - val_accuracy: 0.8875\n",
      "Epoch 257/400\n",
      " - 0s - loss: 0.4036 - accuracy: 0.8431 - val_loss: 0.3496 - val_accuracy: 0.8750\n",
      "Epoch 258/400\n",
      " - 0s - loss: 0.4039 - accuracy: 0.8167 - val_loss: 0.3583 - val_accuracy: 0.8875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/400\n",
      " - 0s - loss: 0.4092 - accuracy: 0.8375 - val_loss: 0.3519 - val_accuracy: 0.8625\n",
      "Epoch 260/400\n",
      " - 0s - loss: 0.3982 - accuracy: 0.8375 - val_loss: 0.3530 - val_accuracy: 0.8750\n",
      "Epoch 261/400\n",
      " - 0s - loss: 0.4015 - accuracy: 0.8264 - val_loss: 0.3527 - val_accuracy: 0.8750\n",
      "Epoch 262/400\n",
      " - 0s - loss: 0.3968 - accuracy: 0.8403 - val_loss: 0.3491 - val_accuracy: 0.8625\n",
      "Epoch 263/400\n",
      " - 0s - loss: 0.4113 - accuracy: 0.8111 - val_loss: 0.3674 - val_accuracy: 0.8875\n",
      "Epoch 264/400\n",
      " - 0s - loss: 0.4262 - accuracy: 0.8194 - val_loss: 0.3660 - val_accuracy: 0.8750\n",
      "Epoch 265/400\n",
      " - 0s - loss: 0.4100 - accuracy: 0.8264 - val_loss: 0.3610 - val_accuracy: 0.8750\n",
      "Epoch 266/400\n",
      " - 0s - loss: 0.3993 - accuracy: 0.8347 - val_loss: 0.3512 - val_accuracy: 0.8750\n",
      "Epoch 267/400\n",
      " - 0s - loss: 0.3995 - accuracy: 0.8361 - val_loss: 0.3589 - val_accuracy: 0.8625\n",
      "Epoch 268/400\n",
      " - 0s - loss: 0.3954 - accuracy: 0.8375 - val_loss: 0.3584 - val_accuracy: 0.8750\n",
      "Epoch 269/400\n",
      " - 0s - loss: 0.3948 - accuracy: 0.8458 - val_loss: 0.3523 - val_accuracy: 0.8625\n",
      "Epoch 270/400\n",
      " - 0s - loss: 0.3994 - accuracy: 0.8292 - val_loss: 0.3502 - val_accuracy: 0.8875\n",
      "Epoch 271/400\n",
      " - 0s - loss: 0.3964 - accuracy: 0.8361 - val_loss: 0.3522 - val_accuracy: 0.8750\n",
      "Epoch 272/400\n",
      " - 0s - loss: 0.4005 - accuracy: 0.8389 - val_loss: 0.3554 - val_accuracy: 0.8750\n",
      "Epoch 273/400\n",
      " - 0s - loss: 0.3984 - accuracy: 0.8306 - val_loss: 0.3420 - val_accuracy: 0.8750\n",
      "Epoch 274/400\n",
      " - 0s - loss: 0.3936 - accuracy: 0.8389 - val_loss: 0.3450 - val_accuracy: 0.8750\n",
      "Epoch 275/400\n",
      " - 0s - loss: 0.3950 - accuracy: 0.8403 - val_loss: 0.3480 - val_accuracy: 0.8750\n",
      "Epoch 276/400\n",
      " - 0s - loss: 0.3985 - accuracy: 0.8347 - val_loss: 0.3525 - val_accuracy: 0.8875\n",
      "Epoch 277/400\n",
      " - 0s - loss: 0.3933 - accuracy: 0.8403 - val_loss: 0.3535 - val_accuracy: 0.8625\n",
      "Epoch 278/400\n",
      " - 0s - loss: 0.3975 - accuracy: 0.8347 - val_loss: 0.3497 - val_accuracy: 0.8875\n",
      "Epoch 279/400\n",
      " - 0s - loss: 0.3972 - accuracy: 0.8486 - val_loss: 0.3631 - val_accuracy: 0.8625\n",
      "Epoch 280/400\n",
      " - 0s - loss: 0.4000 - accuracy: 0.8375 - val_loss: 0.3607 - val_accuracy: 0.8875\n",
      "Epoch 281/400\n",
      " - 0s - loss: 0.4113 - accuracy: 0.8306 - val_loss: 0.3648 - val_accuracy: 0.8750\n",
      "Epoch 282/400\n",
      " - 0s - loss: 0.4117 - accuracy: 0.8153 - val_loss: 0.3741 - val_accuracy: 0.8625\n",
      "Epoch 283/400\n",
      " - 0s - loss: 0.4042 - accuracy: 0.8250 - val_loss: 0.3518 - val_accuracy: 0.8625\n",
      "Epoch 284/400\n",
      " - 0s - loss: 0.3949 - accuracy: 0.8458 - val_loss: 0.3530 - val_accuracy: 0.8875\n",
      "Epoch 285/400\n",
      " - 0s - loss: 0.3917 - accuracy: 0.8431 - val_loss: 0.3528 - val_accuracy: 0.8625\n",
      "Epoch 286/400\n",
      " - 0s - loss: 0.3955 - accuracy: 0.8250 - val_loss: 0.3560 - val_accuracy: 0.8875\n",
      "Epoch 287/400\n",
      " - 0s - loss: 0.3975 - accuracy: 0.8444 - val_loss: 0.3546 - val_accuracy: 0.8625\n",
      "Epoch 288/400\n",
      " - 0s - loss: 0.3932 - accuracy: 0.8361 - val_loss: 0.3489 - val_accuracy: 0.8750\n",
      "Epoch 289/400\n",
      " - 0s - loss: 0.3917 - accuracy: 0.8444 - val_loss: 0.3531 - val_accuracy: 0.8625\n",
      "Epoch 290/400\n",
      " - 0s - loss: 0.3919 - accuracy: 0.8417 - val_loss: 0.3566 - val_accuracy: 0.8875\n",
      "Epoch 291/400\n",
      " - 0s - loss: 0.3959 - accuracy: 0.8458 - val_loss: 0.3510 - val_accuracy: 0.8625\n",
      "Epoch 292/400\n",
      " - 0s - loss: 0.3952 - accuracy: 0.8361 - val_loss: 0.3543 - val_accuracy: 0.8875\n",
      "Epoch 293/400\n",
      " - 0s - loss: 0.3938 - accuracy: 0.8403 - val_loss: 0.3578 - val_accuracy: 0.8750\n",
      "Epoch 294/400\n",
      " - 0s - loss: 0.3937 - accuracy: 0.8375 - val_loss: 0.3624 - val_accuracy: 0.8750\n",
      "Epoch 295/400\n",
      " - 0s - loss: 0.3971 - accuracy: 0.8444 - val_loss: 0.3453 - val_accuracy: 0.8625\n",
      "Epoch 296/400\n",
      " - 0s - loss: 0.3919 - accuracy: 0.8417 - val_loss: 0.3396 - val_accuracy: 0.8750\n",
      "Epoch 297/400\n",
      " - 0s - loss: 0.3954 - accuracy: 0.8431 - val_loss: 0.3513 - val_accuracy: 0.8625\n",
      "Epoch 298/400\n",
      " - 0s - loss: 0.3928 - accuracy: 0.8375 - val_loss: 0.3437 - val_accuracy: 0.8875\n",
      "Epoch 299/400\n",
      " - 0s - loss: 0.3920 - accuracy: 0.8375 - val_loss: 0.3536 - val_accuracy: 0.8750\n",
      "Epoch 300/400\n",
      " - 0s - loss: 0.3968 - accuracy: 0.8486 - val_loss: 0.3551 - val_accuracy: 0.8625\n",
      "Epoch 301/400\n",
      " - 0s - loss: 0.3958 - accuracy: 0.8361 - val_loss: 0.3471 - val_accuracy: 0.8750\n",
      "Epoch 302/400\n",
      " - 0s - loss: 0.3929 - accuracy: 0.8389 - val_loss: 0.3438 - val_accuracy: 0.8750\n",
      "Epoch 303/400\n",
      " - 0s - loss: 0.3904 - accuracy: 0.8472 - val_loss: 0.3436 - val_accuracy: 0.8750\n",
      "Epoch 304/400\n",
      " - 0s - loss: 0.3901 - accuracy: 0.8403 - val_loss: 0.3438 - val_accuracy: 0.8750\n",
      "Epoch 305/400\n",
      " - 0s - loss: 0.3906 - accuracy: 0.8431 - val_loss: 0.3436 - val_accuracy: 0.8750\n",
      "Epoch 306/400\n",
      " - 0s - loss: 0.3964 - accuracy: 0.8431 - val_loss: 0.3539 - val_accuracy: 0.8625\n",
      "Epoch 307/400\n",
      " - 0s - loss: 0.3972 - accuracy: 0.8347 - val_loss: 0.3473 - val_accuracy: 0.8875\n",
      "Epoch 308/400\n",
      " - 0s - loss: 0.3968 - accuracy: 0.8292 - val_loss: 0.3513 - val_accuracy: 0.9000\n",
      "Epoch 309/400\n",
      " - 0s - loss: 0.4057 - accuracy: 0.8347 - val_loss: 0.3473 - val_accuracy: 0.8625\n",
      "Epoch 310/400\n",
      " - 0s - loss: 0.3903 - accuracy: 0.8444 - val_loss: 0.3432 - val_accuracy: 0.8750\n",
      "Epoch 311/400\n",
      " - 0s - loss: 0.3915 - accuracy: 0.8486 - val_loss: 0.3398 - val_accuracy: 0.8625\n",
      "Epoch 312/400\n",
      " - 0s - loss: 0.3921 - accuracy: 0.8458 - val_loss: 0.3434 - val_accuracy: 0.8750\n",
      "Epoch 313/400\n",
      " - 0s - loss: 0.3901 - accuracy: 0.8431 - val_loss: 0.3483 - val_accuracy: 0.8625\n",
      "Epoch 314/400\n",
      " - 0s - loss: 0.3880 - accuracy: 0.8431 - val_loss: 0.3496 - val_accuracy: 0.8875\n",
      "Epoch 315/400\n",
      " - 0s - loss: 0.3896 - accuracy: 0.8458 - val_loss: 0.3433 - val_accuracy: 0.8750\n",
      "Epoch 316/400\n",
      " - 0s - loss: 0.3917 - accuracy: 0.8431 - val_loss: 0.3442 - val_accuracy: 0.8750\n",
      "Epoch 317/400\n",
      " - 0s - loss: 0.3903 - accuracy: 0.8500 - val_loss: 0.3535 - val_accuracy: 0.8625\n",
      "Epoch 318/400\n",
      " - 0s - loss: 0.4082 - accuracy: 0.8222 - val_loss: 0.3605 - val_accuracy: 0.8750\n",
      "Epoch 319/400\n",
      " - 0s - loss: 0.4129 - accuracy: 0.8292 - val_loss: 0.3548 - val_accuracy: 0.8750\n",
      "Epoch 320/400\n",
      " - 0s - loss: 0.3927 - accuracy: 0.8333 - val_loss: 0.3491 - val_accuracy: 0.8750\n",
      "Epoch 321/400\n",
      " - 0s - loss: 0.3940 - accuracy: 0.8292 - val_loss: 0.3479 - val_accuracy: 0.8875\n",
      "Epoch 322/400\n",
      " - 0s - loss: 0.3969 - accuracy: 0.8417 - val_loss: 0.3514 - val_accuracy: 0.8625\n",
      "Epoch 323/400\n",
      " - 0s - loss: 0.3954 - accuracy: 0.8319 - val_loss: 0.3391 - val_accuracy: 0.8750\n",
      "Epoch 324/400\n",
      " - 0s - loss: 0.3910 - accuracy: 0.8444 - val_loss: 0.3534 - val_accuracy: 0.8750\n",
      "Epoch 325/400\n",
      " - 0s - loss: 0.3915 - accuracy: 0.8333 - val_loss: 0.3569 - val_accuracy: 0.8625\n",
      "Epoch 326/400\n",
      " - 0s - loss: 0.3949 - accuracy: 0.8403 - val_loss: 0.3509 - val_accuracy: 0.8750\n",
      "Epoch 327/400\n",
      " - 0s - loss: 0.3931 - accuracy: 0.8417 - val_loss: 0.3490 - val_accuracy: 0.8875\n",
      "Epoch 328/400\n",
      " - 0s - loss: 0.3874 - accuracy: 0.8514 - val_loss: 0.3479 - val_accuracy: 0.8625\n",
      "Epoch 329/400\n",
      " - 0s - loss: 0.4006 - accuracy: 0.8194 - val_loss: 0.3665 - val_accuracy: 0.8750\n",
      "Epoch 330/400\n",
      " - 0s - loss: 0.4012 - accuracy: 0.8347 - val_loss: 0.3604 - val_accuracy: 0.8750\n",
      "Epoch 331/400\n",
      " - 0s - loss: 0.3912 - accuracy: 0.8403 - val_loss: 0.3375 - val_accuracy: 0.8750\n",
      "Epoch 332/400\n",
      " - 0s - loss: 0.3912 - accuracy: 0.8417 - val_loss: 0.3455 - val_accuracy: 0.8625\n",
      "Epoch 333/400\n",
      " - 0s - loss: 0.3971 - accuracy: 0.8278 - val_loss: 0.3568 - val_accuracy: 0.8625\n",
      "Epoch 334/400\n",
      " - 0s - loss: 0.3947 - accuracy: 0.8500 - val_loss: 0.3360 - val_accuracy: 0.8750\n",
      "Epoch 335/400\n",
      " - 0s - loss: 0.3876 - accuracy: 0.8431 - val_loss: 0.3441 - val_accuracy: 0.8625\n",
      "Epoch 336/400\n",
      " - 0s - loss: 0.3876 - accuracy: 0.8375 - val_loss: 0.3388 - val_accuracy: 0.8750\n",
      "Epoch 337/400\n",
      " - 0s - loss: 0.3884 - accuracy: 0.8444 - val_loss: 0.3416 - val_accuracy: 0.8625\n",
      "Epoch 338/400\n",
      " - 0s - loss: 0.3877 - accuracy: 0.8458 - val_loss: 0.3527 - val_accuracy: 0.8625\n",
      "Epoch 339/400\n",
      " - 0s - loss: 0.3894 - accuracy: 0.8333 - val_loss: 0.3445 - val_accuracy: 0.8750\n",
      "Epoch 340/400\n",
      " - 0s - loss: 0.3861 - accuracy: 0.8472 - val_loss: 0.3414 - val_accuracy: 0.8750\n",
      "Epoch 341/400\n",
      " - 0s - loss: 0.3848 - accuracy: 0.8514 - val_loss: 0.3406 - val_accuracy: 0.8750\n",
      "Epoch 342/400\n",
      " - 0s - loss: 0.3922 - accuracy: 0.8250 - val_loss: 0.3484 - val_accuracy: 0.8750\n",
      "Epoch 343/400\n",
      " - 0s - loss: 0.3854 - accuracy: 0.8500 - val_loss: 0.3579 - val_accuracy: 0.8625\n",
      "Epoch 344/400\n",
      " - 0s - loss: 0.3884 - accuracy: 0.8403 - val_loss: 0.3480 - val_accuracy: 0.8875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/400\n",
      " - 0s - loss: 0.3868 - accuracy: 0.8486 - val_loss: 0.3595 - val_accuracy: 0.8750\n",
      "Epoch 346/400\n",
      " - 0s - loss: 0.4019 - accuracy: 0.8264 - val_loss: 0.3654 - val_accuracy: 0.8500\n",
      "Epoch 347/400\n",
      " - 0s - loss: 0.4003 - accuracy: 0.8347 - val_loss: 0.3454 - val_accuracy: 0.8625\n",
      "Epoch 348/400\n",
      " - 0s - loss: 0.3903 - accuracy: 0.8389 - val_loss: 0.3427 - val_accuracy: 0.8750\n",
      "Epoch 349/400\n",
      " - 0s - loss: 0.3902 - accuracy: 0.8431 - val_loss: 0.3544 - val_accuracy: 0.8750\n",
      "Epoch 350/400\n",
      " - 0s - loss: 0.3874 - accuracy: 0.8375 - val_loss: 0.3456 - val_accuracy: 0.8750\n",
      "Epoch 351/400\n",
      " - 0s - loss: 0.3930 - accuracy: 0.8444 - val_loss: 0.3402 - val_accuracy: 0.8750\n",
      "Epoch 352/400\n",
      " - 0s - loss: 0.3919 - accuracy: 0.8306 - val_loss: 0.3514 - val_accuracy: 0.8750\n",
      "Epoch 353/400\n",
      " - 0s - loss: 0.3849 - accuracy: 0.8431 - val_loss: 0.3632 - val_accuracy: 0.8750\n",
      "Epoch 354/400\n",
      " - 0s - loss: 0.3862 - accuracy: 0.8431 - val_loss: 0.3581 - val_accuracy: 0.8750\n",
      "Epoch 355/400\n",
      " - 0s - loss: 0.3874 - accuracy: 0.8486 - val_loss: 0.3546 - val_accuracy: 0.8625\n",
      "Epoch 356/400\n",
      " - 0s - loss: 0.3877 - accuracy: 0.8375 - val_loss: 0.3490 - val_accuracy: 0.8875\n",
      "Epoch 357/400\n",
      " - 0s - loss: 0.3942 - accuracy: 0.8431 - val_loss: 0.3602 - val_accuracy: 0.8750\n",
      "Epoch 358/400\n",
      " - 0s - loss: 0.3953 - accuracy: 0.8292 - val_loss: 0.3738 - val_accuracy: 0.8625\n",
      "Epoch 359/400\n",
      " - 0s - loss: 0.3974 - accuracy: 0.8403 - val_loss: 0.3679 - val_accuracy: 0.8750\n",
      "Epoch 360/400\n",
      " - 0s - loss: 0.3980 - accuracy: 0.8167 - val_loss: 0.3463 - val_accuracy: 0.8875\n",
      "Epoch 361/400\n",
      " - 0s - loss: 0.3911 - accuracy: 0.8375 - val_loss: 0.3668 - val_accuracy: 0.8750\n",
      "Epoch 362/400\n",
      " - 0s - loss: 0.3856 - accuracy: 0.8403 - val_loss: 0.3497 - val_accuracy: 0.8750\n",
      "Epoch 363/400\n",
      " - 0s - loss: 0.3849 - accuracy: 0.8444 - val_loss: 0.3413 - val_accuracy: 0.8750\n",
      "Epoch 364/400\n",
      " - 0s - loss: 0.3824 - accuracy: 0.8528 - val_loss: 0.3433 - val_accuracy: 0.8875\n",
      "Epoch 365/400\n",
      " - 0s - loss: 0.3832 - accuracy: 0.8403 - val_loss: 0.3458 - val_accuracy: 0.8750\n",
      "Epoch 366/400\n",
      " - 0s - loss: 0.3853 - accuracy: 0.8486 - val_loss: 0.3503 - val_accuracy: 0.8625\n",
      "Epoch 367/400\n",
      " - 0s - loss: 0.3820 - accuracy: 0.8500 - val_loss: 0.3470 - val_accuracy: 0.8625\n",
      "Epoch 368/400\n",
      " - 0s - loss: 0.3794 - accuracy: 0.8528 - val_loss: 0.3497 - val_accuracy: 0.8625\n",
      "Epoch 369/400\n",
      " - 0s - loss: 0.3869 - accuracy: 0.8347 - val_loss: 0.3469 - val_accuracy: 0.8750\n",
      "Epoch 370/400\n",
      " - 0s - loss: 0.3863 - accuracy: 0.8431 - val_loss: 0.3425 - val_accuracy: 0.8875\n",
      "Epoch 371/400\n",
      " - 0s - loss: 0.3831 - accuracy: 0.8444 - val_loss: 0.3451 - val_accuracy: 0.8625\n",
      "Epoch 372/400\n",
      " - 0s - loss: 0.3807 - accuracy: 0.8556 - val_loss: 0.3414 - val_accuracy: 0.8625\n",
      "Epoch 373/400\n",
      " - 0s - loss: 0.3842 - accuracy: 0.8472 - val_loss: 0.3401 - val_accuracy: 0.8625\n",
      "Epoch 374/400\n",
      " - 0s - loss: 0.3841 - accuracy: 0.8514 - val_loss: 0.3524 - val_accuracy: 0.8625\n",
      "Epoch 375/400\n",
      " - 0s - loss: 0.3943 - accuracy: 0.8264 - val_loss: 0.3605 - val_accuracy: 0.8750\n",
      "Epoch 376/400\n",
      " - 0s - loss: 0.3939 - accuracy: 0.8389 - val_loss: 0.3622 - val_accuracy: 0.8750\n",
      "Epoch 377/400\n",
      " - 0s - loss: 0.3990 - accuracy: 0.8417 - val_loss: 0.3503 - val_accuracy: 0.8625\n",
      "Epoch 378/400\n",
      " - 0s - loss: 0.3970 - accuracy: 0.8208 - val_loss: 0.3474 - val_accuracy: 0.8625\n",
      "Epoch 379/400\n",
      " - 0s - loss: 0.4048 - accuracy: 0.8319 - val_loss: 0.3714 - val_accuracy: 0.8625\n",
      "Epoch 380/400\n",
      " - 0s - loss: 0.3950 - accuracy: 0.8472 - val_loss: 0.3303 - val_accuracy: 0.8750\n",
      "Epoch 381/400\n",
      " - 0s - loss: 0.3939 - accuracy: 0.8417 - val_loss: 0.3233 - val_accuracy: 0.8750\n",
      "Epoch 382/400\n",
      " - 0s - loss: 0.3847 - accuracy: 0.8500 - val_loss: 0.3499 - val_accuracy: 0.8625\n",
      "Epoch 383/400\n",
      " - 0s - loss: 0.3906 - accuracy: 0.8444 - val_loss: 0.3461 - val_accuracy: 0.8625\n",
      "Epoch 384/400\n",
      " - 0s - loss: 0.3879 - accuracy: 0.8306 - val_loss: 0.3520 - val_accuracy: 0.8875\n",
      "Epoch 385/400\n",
      " - 0s - loss: 0.3837 - accuracy: 0.8514 - val_loss: 0.3633 - val_accuracy: 0.8750\n",
      "Epoch 386/400\n",
      " - 0s - loss: 0.3940 - accuracy: 0.8306 - val_loss: 0.3564 - val_accuracy: 0.8750\n",
      "Epoch 387/400\n",
      " - 0s - loss: 0.3884 - accuracy: 0.8389 - val_loss: 0.3391 - val_accuracy: 0.8750\n",
      "Epoch 388/400\n",
      " - 0s - loss: 0.3824 - accuracy: 0.8458 - val_loss: 0.3436 - val_accuracy: 0.8750\n",
      "Epoch 389/400\n",
      " - 0s - loss: 0.3871 - accuracy: 0.8319 - val_loss: 0.3506 - val_accuracy: 0.8625\n",
      "Epoch 390/400\n",
      " - 0s - loss: 0.3968 - accuracy: 0.8444 - val_loss: 0.3788 - val_accuracy: 0.8750\n",
      "Epoch 391/400\n",
      " - 0s - loss: 0.4215 - accuracy: 0.8069 - val_loss: 0.3577 - val_accuracy: 0.8875\n",
      "Epoch 392/400\n",
      " - 0s - loss: 0.3928 - accuracy: 0.8389 - val_loss: 0.3530 - val_accuracy: 0.8625\n",
      "Epoch 393/400\n",
      " - 0s - loss: 0.3854 - accuracy: 0.8375 - val_loss: 0.3481 - val_accuracy: 0.8625\n",
      "Epoch 394/400\n",
      " - 0s - loss: 0.3821 - accuracy: 0.8514 - val_loss: 0.3503 - val_accuracy: 0.8750\n",
      "Epoch 395/400\n",
      " - 0s - loss: 0.3873 - accuracy: 0.8417 - val_loss: 0.3532 - val_accuracy: 0.8750\n",
      "Epoch 396/400\n",
      " - 0s - loss: 0.3832 - accuracy: 0.8472 - val_loss: 0.3471 - val_accuracy: 0.8625\n",
      "Epoch 397/400\n",
      " - 0s - loss: 0.3951 - accuracy: 0.8264 - val_loss: 0.3390 - val_accuracy: 0.8625\n",
      "Epoch 398/400\n",
      " - 0s - loss: 0.3831 - accuracy: 0.8500 - val_loss: 0.3473 - val_accuracy: 0.8750\n",
      "Epoch 399/400\n",
      " - 0s - loss: 0.3820 - accuracy: 0.8431 - val_loss: 0.3481 - val_accuracy: 0.8750\n",
      "Epoch 400/400\n",
      " - 0s - loss: 0.3791 - accuracy: 0.8514 - val_loss: 0.3453 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x = X_train , y = y_train , validation_split = 0.1 , epochs=400 , batch_size =100 , verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7191011235955056"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test).tolist()\n",
    "\n",
    "def count_accuracy(yhat,y):\n",
    "    length = len(yhat)\n",
    "    count = 0\n",
    "    y = list(y)\n",
    "    for i in range(length):\n",
    "        if yhat[i][0] == y[i]:\n",
    "            count+=1\n",
    "    accuracy = count/length\n",
    "    return(accuracy)\n",
    "\n",
    "count_accuracy(predictions , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
